{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "265b772d",
   "metadata": {},
   "source": [
    "# Terminologies\n",
    "\n",
    "## Encoder\n",
    "- Maps discrete numeric tokens to continous dense representation encoding semantic information.\n",
    "\n",
    "## Decoder\n",
    "- Produces a sequence given the input/dense representation generating one token at a time.\n",
    "\n",
    "## Attention \n",
    "- Dynamically adjusts token representations by adding up the weighted vectors of the token present in its vicinity.\n",
    "\n",
    "## Multi-Head Attention\n",
    "- Works similarly to having multiple convolution kernels each learning different semantics at the feature-level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba02e8a",
   "metadata": {},
   "source": [
    "# Self-Attention Impl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3d2bcf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(123);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "31394080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'It': 0, 'Saarbr端cken': 1, 'Saarland': 2, 'University': 3, 'a': 4, 'called': 5, 'has': 6, 'in': 7, 'is': 8, 'situated': 9}\n"
     ]
    }
   ],
   "source": [
    "corpus = \"Saarbr端cken is situated in Saarland. It has a University called Saarland University.\"\n",
    "dictionary = {s:i for i,s in enumerate(sorted(set(corpus.replace('.','').split())))}\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "00784ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bb721bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 8, 7, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenized sequence\n",
    "sequence = 'Saarland University is in Saarbr端cken.'\n",
    "tokenized_sequence = torch.tensor([dictionary[token] for token in sequence.replace('.','').split()])\n",
    "tokenized_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed46eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2vec\n",
    "# Saarland -> [0.1, 0.2, 0.22, 0.44, 0.1] = v1\n",
    "\n",
    "# attention\n",
    "# Saarland -> 0.5 * v1 + 0.2 *v2 ... + 0.08 * vn\n",
    "\n",
    "# he went to the bank of the river\n",
    "# To the bank of the river he went"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec95495d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention\n",
    "# v1 = [....] -> Saarland\n",
    "## Queries= W_q*v1, Keys=W_k*v1, Values=W_v*v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "773b29f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention hyperparams\n",
    "d = 16 # embedding dimension\n",
    "# dimensions of query === key as we have to compute dot product\n",
    "d_q, d_k, d_v = 24, 24, 28 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c83ba64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 16])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = torch.nn.Embedding(len(dictionary), d)\n",
    "sequence_embeddings = embeddings(tokenized_sequence)\n",
    "sequence_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6abdf774",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_query = torch.nn.Parameter(torch.rand(d_q, d))\n",
    "W_key = torch.nn.Parameter(torch.rand(d_k, d))\n",
    "W_value = torch.nn.Parameter(torch.rand(d_v, d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ff0072",
   "metadata": {},
   "source": [
    "## Computing the Unnormalized Attention Weights\n",
    "\n",
    "<img height=500 width=300 src='https://sebastianraschka.com/images/blog/2023/self-attention-from-scratch/query.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eb62bed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([24, 16]), torch.Size([5, 16]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_query.shape, sequence_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3f5b5d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [d_q, d] x [d, n_seq] -> d_q x n_seq -> [n_seq x d_q]\n",
    "queries = W_query.matmul(sequence_embeddings.T).T\n",
    "# [d_k, d] x [d, n_seq] -> d_k x n_seq -> [n_seq x d_k]\n",
    "keys = W_key.matmul(sequence_embeddings.T).T\n",
    "# [d_v, d] x [d, n_seq] -> d_v x n_seq -> [n_seq x d_v]\n",
    "values = W_value.matmul(sequence_embeddings.T).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9150029",
   "metadata": {},
   "source": [
    "## Normalized Attention Scores\n",
    "\n",
    "Here scaling `1/sqrt(d_k)` ensures that the Euclidean length of the weight vectors will be approximately in the same magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "09d8e368",
   "metadata": {},
   "outputs": [],
   "source": [
    "kq = queries.matmul(keys.T)\n",
    "kq_norm = kq/torch.sqrt(torch.tensor(d_k))\n",
    "kq_norm_softmax = torch.nn.functional.softmax(kq_norm, dim=1)\n",
    "\n",
    "assert kq_norm_softmax.shape == (len(tokenized_sequence), len(tokenized_sequence)), \"unequal dimensions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1eb3babd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## attended weights\n",
    "attention_res = values.T.matmul(kq_norm_softmax.T).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbc8333",
   "metadata": {},
   "source": [
    "## Multi-headed Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "dbd55718",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_heads = 3\n",
    "\n",
    "W_query = torch.nn.Parameter(torch.rand(n_heads, d_q, d))\n",
    "W_key = torch.nn.Parameter(torch.rand(n_heads, d_k, d))\n",
    "W_value = torch.nn.Parameter(torch.rand(n_heads, d_v, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "5892ed93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 24, 16]), torch.Size([3, 16, 5]))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_query.shape, stacked_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "198a0ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extend the input to work with all heads\n",
    "stacked_inputs = sequence_embeddings.T.repeat(n_heads, 1, 1)\n",
    "\n",
    "multihead_keys = torch.bmm(W_query, stacked_inputs)\n",
    "multihead_queries = torch.bmm(W_key, stacked_inputs).permute(0, 2, 1)\n",
    "multihead_values = torch.bmm(W_value, stacked_inputs).permute(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "d30a63a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 5, 24]), torch.Size([3, 24, 5]))"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multihead_queries.shape, multihead_keys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "ec88d1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "kq_multihead = multihead_queries.bmm(multihead_keys)\n",
    "kq_multihead_norm = kq_multihead/torch.sqrt(torch.tensor(d_k))\n",
    "attention_result_multihead = kq_multihead_norm.bmm(multihead_values)\n",
    "\n",
    "attention_concat = attention_result_multihead.reshape(n_heads* len(tokenized_sequence), d_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "c23045d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 28])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_concat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "1ee84533",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = torch.nn.Linear(28, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "5e66d120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 64])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(attention_concat).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994dbd79",
   "metadata": {},
   "source": [
    "## Cross-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "2d5a84f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have another sentence for performing cross attention\n",
    "sequence2 = 'Saarland has Saarbr端cken.'\n",
    "tokenized_sequence2 = torch.tensor([dictionary[token] for token in sequence.replace('.','').split()])\n",
    "sequence_embeddings2 = embeddings(tokenized_sequence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "6571d2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extend the input to work with all heads\n",
    "stacked_inputs2 = sequence_embeddings2.T.repeat(n_heads, 1, 1)\n",
    "\n",
    "multihead_queries2 = torch.bmm(W_key, stacked_inputs2).permute(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "47c75c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 28])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kq_multihead2 = multihead_queries2.bmm(multihead_keys)\n",
    "kq_multihead_norm2 = kq_multihead2/torch.sqrt(torch.tensor(d_k))\n",
    "attention_result_multihead2 = kq_multihead_norm2.bmm(multihead_values)\n",
    "\n",
    "attention_concat2 = attention_result_multihead2.reshape(n_heads* len(tokenized_sequence2), d_v)\n",
    "attention_concat2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "5a08f071",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = torch.nn.Linear(28, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "83599801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 64])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(attention_concat2).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

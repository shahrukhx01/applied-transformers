{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e7452b0",
   "metadata": {},
   "source": [
    "# Terminologies\n",
    "\n",
    "## Encoder\n",
    "- Maps discrete numeric tokens to continous dense representation encoding semantic information.\n",
    "\n",
    "## Decoder\n",
    "- Produces a sequence given the input/dense representation generating one token at a time.\n",
    "\n",
    "## Attention \n",
    "- Dynamically adjusts token representations by adding up the weighted vectors of the token present in its vicinity.\n",
    "\n",
    "## Multi-Head Attention\n",
    "- Works similarly to having multiple convolution kernels each learning different semantics at the feature-level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc40be40",
   "metadata": {},
   "source": [
    "# Self-Attention Impl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0296dddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# He went to the bank to deposit money\n",
    "# He went to the bank of the river"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a635fa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(123);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40065a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'It': 0, 'Saarbrücken': 1, 'Saarland': 2, 'University': 3, 'a': 4, 'called': 5, 'has': 6, 'in': 7, 'is': 8, 'situated': 9}\n"
     ]
    }
   ],
   "source": [
    "corpus = \"Saarbrücken is situated in Saarland. It has a University called Saarland University.\"\n",
    "dictionary = {s:i for i,s in enumerate(sorted(set(corpus.replace('.','').split())))}\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43cb0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <unk>, <pad>, <s>, </s>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b3219e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b6df6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 8, 7, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenized sequence\n",
    "sequence = 'Saarland University is in Saarbrücken.'\n",
    "tokenized_sequence = torch.tensor([dictionary[token] for token in sequence.replace('.','').split()])\n",
    "tokenized_sequence\n",
    "#q-> Saarland\n",
    "# K [Saarland, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3a1f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2vec\n",
    "# Saarland -> [0.1, 0.2, 0.22, 0.44, 0.1] = v1\n",
    "\n",
    "# attention\n",
    "# Saarland -> 0.5 * v1 + 0.2 *v2 ... + 0.08 * vn\n",
    "\n",
    "# he went to the bank of the river\n",
    "# To the bank of the river he went"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0891baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention\n",
    "# v1 = [....] -> Saarland\n",
    "## Queries= W_q*v1, Keys=W_k*v1, Values=W_v*v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39583225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention hyperparams\n",
    "d = 16 # embedding dimension\n",
    "# dimensions of query === key as we have to compute dot product\n",
    "d_q, d_k, d_v = 24, 24, 28 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e355b3cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 16])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = torch.nn.Embedding(len(dictionary), d)\n",
    "sequence_embeddings = embeddings(tokenized_sequence)\n",
    "sequence_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f24a0121",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_query = torch.nn.Parameter(torch.rand(d_q, d))\n",
    "W_key = torch.nn.Parameter(torch.rand(d_k, d))\n",
    "W_value = torch.nn.Parameter(torch.rand(d_v, d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2064051f",
   "metadata": {},
   "source": [
    "## Computing the Unnormalized Attention Weights\n",
    "\n",
    "<img height=500 width=300 src='https://sebastianraschka.com/images/blog/2023/self-attention-from-scratch/query.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fe62180c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([24, 16]), torch.Size([5, 16]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_query.shape, sequence_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5a04ff94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [d_q, d] x [d, n_seq] -> d_q x n_seq -> [n_seq x d_q]\n",
    "queries = W_query.matmul(sequence_embeddings.T).T\n",
    "# [d_k, d] x [d, n_seq] -> d_k x n_seq -> [n_seq x d_k]\n",
    "keys = W_key.matmul(sequence_embeddings.T).T\n",
    "# [d_v, d] x [d, n_seq] -> d_v x n_seq -> [n_seq x d_v]\n",
    "values = W_value.matmul(sequence_embeddings.T).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4696fbef",
   "metadata": {},
   "source": [
    "## Normalized Attention Scores\n",
    "\n",
    "Here scaling `1/sqrt(d_k)` ensures that the Euclidean length of the weight vectors will be approximately in the same magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabf8ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saarland is good\n",
    "#q * K.T/sqrt(d_k) [1, n_seq] -> [0.5, 0.4, 0.1]\n",
    "# [0.9, 0.1, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "0a253593",
   "metadata": {},
   "outputs": [],
   "source": [
    "kq = queries.matmul(keys.T)\n",
    "kq_norm = kq/torch.sqrt(torch.tensor(d_k))\n",
    "kq_norm_softmax = torch.nn.functional.softmax(kq_norm, dim=1)\n",
    "\n",
    "assert kq_norm_softmax.shape == (len(tokenized_sequence), len(tokenized_sequence)), \"unequal dimensions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "38a615d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## attended weights\n",
    "attention_res = values.T.matmul(kq_norm_softmax.T).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52064ec1",
   "metadata": {},
   "source": [
    "## Multi-headed Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ef979be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model = 512\n",
    "n_heads = 8\n",
    "512//8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0abe4520",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_heads = 3\n",
    "# extend the input to work with all heads\n",
    "stacked_inputs = sequence_embeddings.T.repeat(n_heads, 1, 1)\n",
    "\n",
    "W_query = torch.nn.Parameter(torch.rand(n_heads, d_q, d))\n",
    "W_key = torch.nn.Parameter(torch.rand(n_heads, d_k, d))\n",
    "W_value = torch.nn.Parameter(torch.rand(n_heads, d_v, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d75332ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 24, 16]), torch.Size([3, 16, 5]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_query.shape, stacked_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbf93c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "multihead_keys = torch.bmm(W_query, stacked_inputs)\n",
    "multihead_queries = torch.bmm(W_key, stacked_inputs).permute(0, 2, 1)\n",
    "multihead_values = torch.bmm(W_value, stacked_inputs).permute(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5581197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 5, 24]), torch.Size([3, 24, 5]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multihead_queries.shape, multihead_keys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14db528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kq_multihead = multihead_queries.bmm(multihead_keys)\n",
    "kq_multihead_norm = kq_multihead/torch.sqrt(torch.tensor(d_k))\n",
    "attention_result_multihead = kq_multihead_norm.bmm(multihead_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d219db",
   "metadata": {},
   "outputs": [],
   "source": [
    "8, 5, 64 -> 5, 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "933b483b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 28])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_result_multihead.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8efefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_concat = attention_result_multihead.reshape(n_heads* len(tokenized_sequence), d_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "9101fc65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 28])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_concat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "30635b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = torch.nn.Linear(28, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "df2d89da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 64])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(attention_concat).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d9d12c",
   "metadata": {},
   "source": [
    "## Cross-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5ff802",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Saarland has Saarbrücken.\" -> memory Softmax({Saarland, Saarbrucken})->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bce093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have another sentence for performing cross attention\n",
    "sequence2 = '<s>'\n",
    "tokenized_sequence2 = torch.tensor([dictionary[token] for token in sequence.replace('.','').split()])\n",
    "sequence_embeddings2 = embeddings(tokenized_sequence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "5dcdd2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extend the input to work with all heads\n",
    "stacked_inputs2 = sequence_embeddings2.T.repeat(n_heads, 1, 1)\n",
    "\n",
    "multihead_queries2 = torch.bmm(W_key, stacked_inputs2).permute(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "438e9ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 28])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kq_multihead2 = multihead_queries2.bmm(multihead_keys)\n",
    "kq_multihead_norm2 = kq_multihead2/torch.sqrt(torch.tensor(d_k))\n",
    "attention_result_multihead2 = kq_multihead_norm2.bmm(multihead_values)\n",
    "\n",
    "attention_concat2 = attention_result_multihead2.reshape(n_heads* len(tokenized_sequence2), d_v)\n",
    "attention_concat2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "8c3b8a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = torch.nn.Linear(28, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "78b4c98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 64])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(attention_concat2).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
